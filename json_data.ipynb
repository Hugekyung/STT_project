{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    return x.replace(\"(\",\"\").replace(\")\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace('\"',\"\").replace(\"'\",\"\").replace(\"=\",\"\")\n",
    "def _get_ngrams(n, text):\n",
    "    \"\"\"Calcualtes n-grams.\n",
    "\n",
    "    Args:\n",
    "      n: which n-grams to calculate\n",
    "      text: An array of tokens\n",
    "\n",
    "    Returns:\n",
    "      A set of n-grams\n",
    "    \"\"\"\n",
    "    ngram_set = set()\n",
    "    text_length = len(text)\n",
    "    max_index_ngram_start = text_length - n\n",
    "    for i in range(max_index_ngram_start + 1):\n",
    "        ngram_set.add(tuple(text[i:i + n]))\n",
    "    return ngram_set\n",
    "\n",
    "\n",
    "def _get_word_ngrams(n, sentences):\n",
    "    \"\"\"Calculates word n-grams for multiple sentences.\n",
    "    \"\"\"\n",
    "    assert len(sentences) > 0\n",
    "    assert n > 0\n",
    "\n",
    "    # words = _split_into_words(sentences)\n",
    "\n",
    "    words = sum(sentences, [])\n",
    "    # words = [w for w in words if w not in stopwords]\n",
    "    return _get_ngrams(n, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "def load_data(row):\n",
    "    kkma=Kkma()\n",
    "    article=row[\"body\"]\n",
    "    abstract=row[\"tgt\"]\n",
    "#     article=article.text\n",
    "#     abstract=tgt_text\n",
    "    src_txt=kkma.sentences(article)\n",
    "    tgt_txt=kkma.sentences(abstract)\n",
    "\n",
    "    source=[kkma.morphs(clean(sen)) for sen in src_txt]\n",
    "    tgt=[kkma.morphs(clean(sen)) for sen in tgt_txt]\n",
    "    return source,tgt\n",
    "def _format_to_lines(f):\n",
    "    source, tgt = load_data(f)\n",
    "    return {'src': source, 'tgt': tgt}\n",
    "\n",
    "def format_to_lines():\n",
    "    for corpus_type in ['valid', 'test', 'train']:\n",
    "        df=pd.read_csv(corpus_type+\"_data.csv\")\n",
    "        df.apply(_format_to_lines,axis=1).to_json(\"cnndm_sample.\"+corpus_type+\".0\"+\".json\",orient=\"records\")\n",
    "format_to_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
